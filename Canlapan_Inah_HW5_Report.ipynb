{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4434d2",
   "metadata": {},
   "source": [
    "# HW 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6051645",
   "metadata": {},
   "source": [
    "### 1. Conceptual Questions\n",
    "\n",
    "**(a) Given two tables, calculate the mutual information for the two keywords, \"prize\" and \"hello\". Which keyword is more informative for deciding whether or not the email is a spam?**\n",
    "\n",
    "||spam = 1|spam = 0|\n",
    "|:-:|:-:|:-:|\n",
    "|**prize = 1** | $N_{11}$ = 150 | $N_{10}$ = 1000 |\n",
    "|**prize = 0** |$N_{01}$ = 10 | $N_{00}$ = 15000 |\n",
    "\n",
    "$I(prize, spam) = \\frac{N_{11}}{N}log_2\\frac{NN_{11}}{N_{1.}N_{.1}} + \\frac{N_{01}}{N}log_2\\frac{NN_{01}}{N_{0.}N_{.1}} + \\frac{N_{10}}{N}log_2\\frac{NN_{10}}{N_{1.}N_{.0}} + \\frac{N_{00}}{N}log_2\\frac{NN_{00}}{N_{0.}N_{.0}}$  \n",
    "\n",
    "$N = 150+1000+10+15000 = 16160$  \n",
    "$N_{1.} = 150 + 1000 = 1150$  \n",
    "$N_{.1} = 150 + 10 = 160$    \n",
    "$N_{0.} = 10 + 15000 = 15010$  \n",
    "$N_{.0} = 1000 + 15000 = 16000$     \n",
    "\n",
    "$I(prize, spam) = \\frac{150}{16160}log_2\\frac{16160*150}{1150*160} + \\frac{10}{16160}log_2\\frac{16160*10}{15010*160} + \\frac{1000}{16160}log_2\\frac{16160*1000}{1150*16000} + \\frac{15000}{16160}log_2\\frac{16160*15000}{15010*16000}$  \n",
    "$= 0.03296011876395397$\n",
    "\n",
    "||spam = 1|spam = 0|\n",
    "|:-:|:-:|:-:|\n",
    "|**hello = 1** | $N_{11}$ = 155 | $N_{10}$ = 14000 |\n",
    "|**hello = 0** |$N_{01}$ = 5 | $N_{00}$ = 2000 |\n",
    "\n",
    "$I(hello, spam) = \\frac{N_{11}}{N}log_2\\frac{NN_{11}}{N_{1.}N_{.1}} + \\frac{N_{01}}{N}log_2\\frac{NN_{01}}{N_{0.}N_{.1}} + \\frac{N_{10}}{N}log_2\\frac{NN_{10}}{N_{1.}N_{.0}} + \\frac{N_{00}}{N}log_2\\frac{NN_{00}}{N_{0.}N_{.0}}$  \n",
    "$= 0.0007839352232340266$ \n",
    "\n",
    "$N = 155+14000+5+2000 = 16160$  \n",
    "$N_{1.} = 155 + 14000 = 14155$  \n",
    "$N_{.1} = 155 + 5 = 160$    \n",
    "$N_{0.} = 5 + 2000 = 2005$  \n",
    "$N_{.0} = 14000 + 2000 = 16000$  \n",
    "\n",
    "Since $I(prize, spam) > I(hello, spam)$, **prize** is more informative for deciding whether or not the email is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fb0a3",
   "metadata": {},
   "source": [
    "**(b) Given two distributions, $f_0 = N(0,1), f_1 = N(1.5,1.1)$, explicitly derive what the CUSUM statistic should be.**  \n",
    " \n",
    "From page 22 the Anomaly Detection lectures notes:  \n",
    "$W_t = max(W_{t-1}+log\\frac{f_1(X_t)}{f_0(X_t)},0)$  \n",
    "\n",
    "Completing the PDF of Normal Distributions:  \n",
    "$f_1(X_t) = N(1.5,1.1) = \\frac{1}{\\sqrt{2\\pi1.1}}e^{\\frac{-1}{2}(\\frac{x-1.5}{\\sqrt{1.1}})^2}$  \n",
    "$f_0(X_t) = N(0,1) = \\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-1}{2}x^2}$  \n",
    "\n",
    "Simplifying:  \n",
    "$\\frac{f_1(X_t)}{f_0(X_t)} = \\frac{1}{\\sqrt{1.1}}e^{\\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2)}$   \n",
    "$log(\\frac{f_1(X_t)}{f_0(X_t)}) = log(\\frac{1}{\\sqrt{1.1}}e^{\\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2)}) = log(\\frac{1}{\\sqrt{1.1}}) + log(e^{\\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2)}) = log(\\frac{1}{\\sqrt{1.1}}) + \\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2) = -log(\\sqrt{1.1})+ \\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2) $  \n",
    "\n",
    "$\\longrightarrow W_t = max(W_{t-1}-log(\\sqrt{1.1})+ \\frac{1}{2}(x^2-(\\frac{x-1.5}{\\sqrt{1.1}})^2),0)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dcefdb",
   "metadata": {},
   "source": [
    "**Plot the CUSUM statistic for a sequence of randomly generated samples that are i.i.d $x_1,...,x_{100} \\backsim f_0, x_{101},...,x_{200} \\backsim f_1$**  \n",
    "<img src=\"cusum_samples.jpg\" width=\"400\"/> <img src=\"cusum_statistic.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d590f",
   "metadata": {},
   "source": [
    "### 2. House Price Dataset\n",
    "The HOUSES dataset contains a collection of recent real estate listings in San Luis Obispo county and around it. The dataset is provided in RealEstate.csv. You may use “one-hot-keying” to expand the categorical variables.  \n",
    "The dataset contains the following useful fields (You may exclude the Location and MLS in your linear regression model).  \n",
    "You can use any package for this question.  \n",
    "Note: We suggest you scale the independent variables (but not the dependent variable). We also suggest you use our suggested seeds, as this dataset is particularly seed dependent.  \n",
    "* Price: the most recent listing price of the house (in dollars).\n",
    "* Bedrooms: number of bedrooms.\n",
    "* Bathrooms: number of bathrooms.\n",
    "* Size: size of the house in square feet.\n",
    "* Price/SQ.ft: price of the house per square foot.\n",
    "* Status: Short Sale, Foreclosure and Regular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113fc55",
   "metadata": {},
   "source": [
    "**(a)  Fit the Ridge regression model to predict Price from all variable. You can use one-hot keying to expand the categorical variable Status. Use 5-fold cross validation to select the regularizer optimal parameter, and show the CV curve. Report the fitted model (i.e., the parameters), and the sum-of-squares residuals. The suggested search range for the regularization parameter is from 1 to 80, and the suggested seed is 2.**\n",
    "\n",
    "The chosen $\\alpha$ is 1 based on the negative mean squared error scoring metric.\n",
    "<img src=\"house_ridge_cv_curve.jpg\" width=\"400\"/>  \n",
    "\n",
    "The fitted model coefficients are:  \n",
    "Intercept = -314766.34852713783  \n",
    "Bedrooms = 24264.47041987  \n",
    "Size = 1579560.26950984  \n",
    "Price/SQ.Ft = 1849370.30103488  \n",
    "Foreclosure = -15396.50807562  \n",
    "Regular = 40911.75979374  \n",
    "Short Sale = -25515.25171813  \n",
    "\n",
    "Sum of Squares Residuals = 17,003,281,203,675"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d0490",
   "metadata": {},
   "source": [
    "**(b) Use lasso to select variables. Use 5-fold cross validation to select the regularizer optimal parameter, and show the CV curve. Report the fitted model (i.e., the parameters selected and their coefficient). Show the Lasso solution path. The suggested search range for the regularization parameter is from 1 to 3000, and the suggested seed is 3.**  \n",
    "\n",
    "The chosen $\\alpha$ is 11 based on the negative mean squared error scoring metric.\n",
    "<img src=\"house_lasso_cv_curve.jpg\" width=\"400\"/>  \n",
    "\n",
    "The fitted model coefficients are:  \n",
    "Intercept = -380005.4024880027  \n",
    "Bedrooms = -71614.75646417  \n",
    "Size = 1741200.2885389  \n",
    "Price/SQ.Ft = 2074627.53267139  \n",
    "Foreclosure = 4610.26062518  \n",
    "Regular = 33538.84775991  \n",
    "Short Sale = -4583.3327755   \n",
    "  \n",
    "Sum of Squares Residuals = 16,330,843,510,219  \n",
    "\n",
    "<img src=\"house_lasso_solution_path.jpg\" width=\"400\"/>  \n",
    "<img src=\"house_lasso_solution_path_log.jpg\" width=\"400\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6360b97",
   "metadata": {},
   "source": [
    "### 3. Medical Imaging Reconstuction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50cf06",
   "metadata": {},
   "source": [
    "**(a) Use Lasso to recover the image and select $\\lambda$ using 10-fold cross validation. Plot the cross-validation error curves and show the recovered image.**\n",
    "\n",
    "To find lambda, I tested multiple ranges and found that smaller values (< 1) of $\\lambda$ worked best. The ideal $\\lambda$ is 0.07.  \n",
    "\n",
    "<img src=\"mri_lasso_cv_curve.jpg\" width=\"400\"/>  \n",
    "\n",
    "Reconstructed Image:\n",
    "<img src=\"mri_lasso_img.jpg\" width=\"400\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a966b36",
   "metadata": {},
   "source": [
    "**(b) To compare, use ridge regression to recover the image. Use $\\lambda$ using 10-fold cross validation. Plot the cross-validation error curves and show the recovered image.**  \n",
    "\n",
    "For ridge regressiosn, larger vaues of $\\lambda$ worked best. The ideal $\\lambda$ is 61.  \n",
    "\n",
    "<img src=\"mri_ridge_cv_curve.jpg\" width=\"400\"/>  \n",
    "Reconstructed Image:\n",
    "<img src=\"mri_ridge_img.jpg\" width=\"400\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7df506",
   "metadata": {},
   "source": [
    "**Which approach gives a better recovered image?**  \n",
    "\n",
    "| Original  | LASSO    | Ridge Regression     | \n",
    "|:--:|:-----------:|:-------:|\n",
    "| <img src=\"mri_original_img.jpg\" width=\"400\"/>  |<img src=\"mri_lasso_img.jpg\" width=\"400\"/>   |<img src=\"mri_ridge_img.jpg\" width=\"400\"/>  |  \n",
    "\n",
    "Ridge regression provides a more noisy reconstructed image with varying shades of grey but you can clearly see all 3 shapes. LASSO provides a less noisy reconstruction but is missing parts of each shape. For the purpose of an MRI, I would say ridge regression provides the better recovered image. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
